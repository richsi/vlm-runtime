## vlm-runtime

Vision language model inference on Rust backend optimized with CUDA kernels.